{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import json\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition:\n",
    "    def __init__(self, feature_idx, operation, split_value):\n",
    "        self.feature_idx = feature_idx\n",
    "        self.operation = operation\n",
    "        self.split_value = split_value\n",
    "\n",
    "    def print_condition(self):\n",
    "        print(f\"Feature {self.feature_idx} {self.operation} {self.split_value}\")\n",
    "\n",
    "    def reverse_condition(self):\n",
    "        if self.operation == \">=\":\n",
    "            new_operation = \"<\"\n",
    "        elif self.operation == '<':\n",
    "            new_operation = \">=\"\n",
    "        else:\n",
    "            # Handle the case where self.operation is neither \">=\" nor \"<\"\n",
    "            raise AssertionError(\"Invalid operation: {}\".format(self.operation))\n",
    "        return Condition(self.feature_idx, new_operation, self.split_value)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Condition):\n",
    "            return (\n",
    "                self.feature_idx == other.feature_idx and\n",
    "                self.operation == other.operation and\n",
    "                self.split_value == other.split_value\n",
    "            )\n",
    "        return False\n",
    "\n",
    "class Path:\n",
    "    def __init__(self, node_path):\n",
    "        self.node_conditions = node_path\n",
    "    \n",
    "    def print_path(self):\n",
    "        path = []\n",
    "        for condition in self.node_conditions:\n",
    "            path += [f\"Feature {condition.feature_idx} {condition.operation} {condition.split_value}\"]\n",
    "        print(' & '.join(path))\n",
    "\n",
    "\n",
    "class Rule: \n",
    "    def __init__(self, node_path:Path, node_pred:list):\n",
    "        self.node_path = node_path\n",
    "        self.node_pred_then = node_pred[0]\n",
    "        self.node_pred_else = node_pred[1]\n",
    "\n",
    "    \n",
    "    def print_rule(self):\n",
    "        path = []\n",
    "        for condition in self.node_path.node_conditions:\n",
    "            path += [f\"Feature {condition.feature_idx} {condition.operation} {condition.split_value}\"]\n",
    "        print(' & '.join(path) + f\" then Y = {self.node_pred_then} else Y = {self.node_pred_else}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/norahallqvist/Code/SIRUS/results/example_rules_dict.json', 'r') as json_file:\n",
    "    rules_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_formated_rules(rules_dict):\n",
    "    rules_flatten  = {}\n",
    "    for tree_idx, tree_rules in rules_dict.items():\n",
    "        for path, rule in tree_rules.items():\n",
    "            rules_flatten[path] = rule\n",
    "\n",
    "    #TODO: check that list is even (assumed that there are 6 rules)\n",
    "\n",
    "    iter_rules_items = iter(rules_flatten.items())\n",
    "    all_rules = []\n",
    "\n",
    "    for (path_right, node_pred_right), (path_left, node_pred_left) in zip(iter_rules_items, iter_rules_items):\n",
    "\n",
    "        #double check that the same node is being compared\n",
    "        numeric_values_right = [int(float(value)) for value in re.findall(r'\\d+\\.\\d+', path_right)]\n",
    "        numeric_sum_right = sum(numeric_values_right)\n",
    "\n",
    "        numeric_values_left = [int(float(value)) for value in re.findall(r'\\d+\\.\\d+', path_left)]\n",
    "        numeric_sum_left = sum(numeric_values_left)\n",
    "\n",
    "        if numeric_sum_right != numeric_sum_left:\n",
    "            raise ValueError(\"Error: Feature mismatch (i.e the same node is not being processed)\")\n",
    "\n",
    "        conditions = path_right.split(\"&\")\n",
    "        path_conditions = []\n",
    "        for condition in conditions:\n",
    "            feature, operation, split = (condition.strip()).split(\" \")[1:]\n",
    "            path_conditions.append(Condition(int(feature), operation, float(split)))\n",
    "        path_to_node = Path(path_conditions)\n",
    "        node_rule = Rule(path_to_node, [float(node_pred_right), float(node_pred_left)])\n",
    "        all_rules.append(node_rule)\n",
    "    \n",
    "    return all_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 22 < 106.4 then Y = 0.0 else Y = 1.0\n",
      "Feature 22 < 106.4 & Feature 27 < 0.18144000000000002 then Y = 0.0 else Y = 1.0\n",
      "Feature 22 >= 106.4 & Feature 22 < 117.7 then Y = 1.0 else Y = 1.0\n",
      "Feature 20 < 16.145999999999997 then Y = 0.0 else Y = 1.0\n",
      "Feature 20 < 16.145999999999997 & Feature 7 < 0.03483 then Y = 0.0 else Y = 0.0\n",
      "Feature 20 >= 16.145999999999997 & Feature 7 < 0.049199999999999994 then Y = 0.0 else Y = 1.0\n"
     ]
    }
   ],
   "source": [
    "all_rules =return_formated_rules(rules_dict)\n",
    "for r in all_rules:\n",
    "    r.print_rule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if condition 1 -> condition 2\n",
    "def _implies(condition1, condition2):\n",
    "    if condition1.feature_idx == condition1.feature_idx:\n",
    "        if condition1.operation == \"<\":\n",
    "            if condition2.operation == \"<\":\n",
    "                return condition1.split_value <= condition2.split_value \n",
    "            else: \n",
    "                return False \n",
    "        else:\n",
    "            if condition2.feature_idx == \">=\":\n",
    "                return condition1.split_value >= condition2.split_value\n",
    "            else: \n",
    "                return False \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if ondition 1 & condition 2 --> Rule \n",
    "def _implies_condition(condition:(Condition, Condition), rule: Rule) -> bool:\n",
    "    cond1, cond2 = condition\n",
    "    implied = [any(_implies(cond1, condition) or _implies(cond2, condition) for condition in rule.node_path.node_conditions)]\n",
    "    return all(implied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _feature_space(rules:list, cond1:Condition, cond2:Condition):\n",
    "    num_rules = len(rules)\n",
    "    data_matrix = np.empty((4, num_rules + 1), dtype=bool)\n",
    "    data_matrix[:,0] = np.ones((4))\n",
    "\n",
    "    reverse_cond1 = cond1.reverse_condition()\n",
    "    reverse_cond2 = cond2.reverse_condition()\n",
    "\n",
    "    for col_idx in range(1, (num_rules + 1)):\n",
    "        cur_rule = rules[col_idx - 1]\n",
    "        data_matrix[0, col_idx] = _implies_condition((cond1, cond2), cur_rule)\n",
    "        data_matrix[1, col_idx] = _implies_condition((cond1, reverse_cond2), cur_rule)\n",
    "        data_matrix[2, col_idx] = _implies_condition((reverse_cond1, cond2), cur_rule)\n",
    "        data_matrix[3, col_idx] = _implies_condition((reverse_cond1, reverse_cond2), cur_rule)\n",
    "    \n",
    "    return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a vector of unique left splits for `rules`.\n",
    "These splits will be used to form `(A, B)` pairs and generate the feature space.\n",
    "For example, the pair `x[i, 1] < 32000` (A) and `x[i, 3] < 64` (B) will be used to generate\n",
    "the feature space `A & B`, `A & !B`, `!A & B`, `!A & !B`.\n",
    "\"\"\"\n",
    "\n",
    "def get_left_condition(condition:Condition):\n",
    "    if condition.operation != \"<\":\n",
    "        return condition.reverse_condition()\n",
    "    return condition\n",
    "\n",
    "def is_unqiue_condition(condition:Condition, set_of_condition:list):\n",
    "    for cond_in_set in set_of_condition:\n",
    "        if cond_in_set.split_value == condition.split_value and cond_in_set.feature_idx == condition.feature_idx:\n",
    "            return False\n",
    "    return True \n",
    "\n",
    "def _unique_left_conditions(rules:list):\n",
    "    set_of_conditions = []\n",
    "    for rule in rules:\n",
    "        for condition in rule.node_path.node_conditions:\n",
    "            #get the left version of the condition (if already left remain left)\n",
    "            condition = get_left_condition(condition)\n",
    "            if is_unqiue_condition(condition, set_of_conditions): \n",
    "                set_of_conditions.append(condition)\n",
    "    return set_of_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 22 < 106.4\n",
      "Feature 27 < 0.18144000000000002\n",
      "Feature 22 < 117.7\n",
      "Feature 20 < 16.145999999999997\n",
      "Feature 7 < 0.03483\n",
      "Feature 7 < 0.049199999999999994\n"
     ]
    }
   ],
   "source": [
    "for con in _unique_left_conditions(all_rules):\n",
    "    con.print_condition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return whether some rule is either related to `A` or `B` or both.\n",
    "Here, it is very important to get rid of rules which are about the same feature but different thresholds.\n",
    "Otherwise, rules will be wrongly classified as linearly dependent in the next step.\n",
    "\"\"\"\n",
    "def _related_rule(rule:Rule, cond1:Condition, cond2:Condition):\n",
    "    assert cond1.operation == '<', \"Assertion failed: cond1 should be < (something is wrong with _unique_left_conditions)\"\n",
    "    assert cond2.operation == '<', \"Assertion failed: cond 2 should be < (something is wrong with _unique_left_conditions)\"\n",
    "    conditions_in_path = rule.node_path.node_conditions\n",
    "    if len(conditions_in_path) == 1:\n",
    "        single_condtion = conditions_in_path[0]\n",
    "        left_condition = get_left_condition(single_condtion)\n",
    "        return left_condition == cond1 or left_condition == cond2 \n",
    "    elif len(conditions_in_path) == 2:\n",
    "        single_condtion_1, single_condtion_2 = conditions_in_path\n",
    "        left_condtion_1, left_condtion_2 = get_left_condition(single_condtion_1), get_left_condition(single_condtion_2)\n",
    "        return (left_condtion_1 == cond1 and left_condtion_2 == cond2) or (left_condtion_1 == cond2 and left_condtion_2 == cond1)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of conditions in the path. Expected 1 or 2 conditions, but got {} conditions.\".format(len(conditions_in_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a vector of booleans with a true for every rule in `rules` that is linearly dependent on a combination of the previous rules.\n",
    "To find rules for this method, collect all rules containing some feature for each pair of features.\n",
    "That should be a fairly quick way to find subsets that are easy to process.\n",
    "\"\"\"\n",
    "\n",
    "def _linearly_dependent(rules: list, cond1:Condition, cond2:Condition):\n",
    "    data_matrix = _feature_space(rules, cond1, cond2)\n",
    "    num_rules = len(rules)\n",
    "    dependent = np.empty(num_rules, dtype=bool)\n",
    "    atol = 1e-6\n",
    "    current_rank = np.linalg.matrix_rank(data_matrix[:, 0], tol=atol)\n",
    "\n",
    "    for i in range(num_rules):\n",
    "\n",
    "        #adding an additional rank and checking if rank increases or decreases\n",
    "        new_rank = np.linalg.matrix_rank(data_matrix[:, 0:i+2], tol=atol)\n",
    "        if current_rank < new_rank:\n",
    "            dependent[i] = False\n",
    "            current_rank = new_rank\n",
    "        else:\n",
    "            dependent[i] = True\n",
    "\n",
    "    return dependent\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_linearly_dependent(all_rules, all_rules[2].node_path.node_conditions[0].reverse_condition(), all_rules[2].node_path.node_conditions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return all unique pairs of elements in `V`.\n",
    "More formally, return all pairs (v_i, v_j) where i < j.\n",
    "\"\"\"\n",
    "def _create_unique_pairs(unique_conditions:list):\n",
    "    num_conditions = len(unique_conditions)\n",
    "    unique_condition_pairs = []\n",
    "\n",
    "    for i in range(num_conditions):\n",
    "        left = unique_conditions[i]\n",
    "        for j in range(num_conditions):\n",
    "            if i < j: \n",
    "                right = unique_conditions[j]\n",
    "                unique_condition_pairs.append((left, right))\n",
    "\n",
    "    return unique_condition_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a vector of rules that are not linearly dependent on any other rule.\n",
    "\n",
    "This is done by considering each pair of splits.\n",
    "For example, considers the pair `x[i, 1] < 32000` (A) and `x[i, 3] < 64` (B).\n",
    "Then, for each rule, it checks whether the rule is linearly dependent on the pair.\n",
    "As soon as a dependent rule is found, it is removed from the set to avoid considering it again.\n",
    "If we don't do this, we might remove some rule `r` that causes another rule to be linearly\n",
    "dependent in one related set, but then is removed in another related set.\n",
    "\"\"\"\n",
    "def _filter_linearly_dependent_rules(rules:list):\n",
    "    unique_conditions = _unique_left_conditions(rules)\n",
    "    # TODO: need to sort the rules by gap size??\n",
    "    condition_pairs = _create_unique_pairs(unique_conditions) #get the lower traingle of all combinations\n",
    "    independent_rules = copy.deepcopy(rules)\n",
    "\n",
    "\n",
    "    for (cond1, cond2) in condition_pairs:\n",
    "        independent_rules_idxs = [rule_idx for rule_idx, rule in enumerate(independent_rules) if _related_rule(rule, cond1, cond2)]\n",
    "        independent_rules_subset = [independent_rules[i] for i in independent_rules_idxs]\n",
    "        dependent_subset = _linearly_dependent(independent_rules_subset, cond1, cond2) #a list indicating if rule is dependent or not\n",
    "\n",
    "        assert len(independent_rules_idxs) == len(independent_rules_subset)\n",
    "        assert len(dependent_subset) == len(independent_rules_subset)\n",
    "\n",
    "        dependent_indexes = [independent_rules_idxs[i] for i, is_dependent in enumerate(dependent_subset) if is_dependent]\n",
    "        dependent_indexes.sort() #is this needed?? #TODO: CHECK if this is needed \n",
    "        for index in reversed(dependent_indexes):\n",
    "            independent_rules.pop(index)\n",
    "\n",
    "    return independent_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_rules = _filter_linearly_dependent_rules(all_rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('cs109a')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "683a8f5228cdb2dfe20440e7c79750b7ef6077ddd22e2c437eb1bcaa2db9b8fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
